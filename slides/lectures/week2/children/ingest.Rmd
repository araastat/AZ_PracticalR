
---
class: middle, center, inverse

# Data ingestion

---

## Data ingestion

Unlike Excel, you have to pull data into R for R to operate on it

Typically your data is in some sort of file (Excel, csv, sas7bdat, txt)

You need to find a way to pull it into R

The GUI you've used is one way, but not very programmatic. This is a problem for verification and reproducibility.

---

## The `readr` package

```{r, echo=F}
d <- tribble(~Function, ~Reads,
             'read_csv()', 'Comma separated values',
             'read_csv2()', 'Semi-colon separated values',
             'read_delim()', 'General delimited files',
             'read_fwf()', 'Fixed width files',
             'read_tsv()', 'Tab delimited values')
knitr::kable(d) %>% 
  kableExtra::kable_styling()
```

Compared to data ingestion functions in base R, these are

1. around 10x faster
1. returns _tibbles_ (enhanced data.frame)
1. Have better defaults
---

## Data ingestion

The **readr** package is meant to ingest rectangular data.

There are of course many other data formats that might need to be read. R provides functionality to read many of these.

```{r 03-DataIngestionMunging-8, echo=F}
b <- tribble(
  ~Type, ~Function, ~Package,~Notes,
  "csv", "read_csv", "readr", "Takes care of formatting",
  "csv", "read.csv", "base", "Built in",
  "csv", "fread", "data.table", "Fastest",
  "Excel", "read_excel", "readxl",'',
  'sas7bdat','read_sas', 'haven','SAS format',
  'json', 'read_json', 'jsonlite', 'JSON format'
)
knitr::kable(d, format='html')
```

---

## Example data sets

We will use the following files for examples in this section

1. BreastCancer_Clinical.csv
1. BreastCancer.xlsx
1. sydneybeaches3.csv

Take a couple of minutes and download these files into your RStudio Project

```{r, echo=F}
countdown(minutes=3)
```

> Note where you store the data files within your project. Your path will not be the same as mine, since I probably have a different directory structure than you

> You'll see a lot of `..` in my file paths. This means _go up one level_ in the hierarchy of file paths.
---

## Data ingestion



```{r 03-DataIngestionMunging-9, message=F}
brca_clinical <- readr::read_csv('../../data/BreastCancer_Clinical.csv')
brca_clinical2 <- data.table::fread('../../data/BreastCancer_Clinical.csv')
```

.pull-left[
```{r 03-DataIngestionMunging-10}
str(brca_clinical)
```
]
.pull-right[
```{r 03-DataIngestionMunging-11}
str(brca_clinical2)
```
]

---

## A note on two "super"-data.frame objects

.pull-left[
A `tibble`
```{r 03-DataIngestionMunging-12, echo=F}
head(brca_clinical)
```
]
.pull-right[
A `data.table`

```{r 03-DataIngestionMunging-13, echo=F}
head(brca_clinical2)
```
]

---

## A note on two "super"-data.frame objects

+ A `tibble` works pretty much like any `data.frame`, but the printing is a little saner
+ A `data.table` is faster, has more inherent functionality, but has a very different syntax


--

Suggested modifications:

+ If using `fread`, convert the resulting object to a `data.frame` or `tibble` using `as_data_frame()` or `as_tibble()`
+ Convert the column names to not have spaces using, for example,

```{r 03-DataIngestionMunging-14}
brca_clinical <- janitor::clean_names(brca_clinical)
```

--

We'll work almost entirely with `tibble`'s and not `data.table`. 

However, if speed is a consideration for you, it might be worth learning to work with data.table objects. Some resources for this are:

- [A gentle introduction to data.table](https://atrebas.github.io/post/2020-06-17-datatable-introduction/)
- [data.table in R: The Complete Beginners Guide](https://www.machinelearningplus.com/data-manipulation/datatable-in-r-complete-guide/)
- [Cheatsheet](https://raw.githubusercontent.com/rstudio/cheatsheets/master/datatable.pdf)


---

## Data ingestion

Note that you **have** to give a name to what you're importing using `read_*` or whatever you're using, otherwise it won't stay in R

```{r 03-DataIngestionMunging-15, eval=F}
brca_clinical <- readr::read_csv('../../data/BreastCancer_Clinical.csv')
```

![](../img/env.png)

> See what happens if you don't give a name to a dataset you ingest.

---

## Reading Excel

You can find the names of the sheets in an Excel file:
```{r 03-DataIngestionMunging-16}
readxl::excel_sheets('../../data/BreastCancer.xlsx')
```

So you can ingest a particular sheet from an Excel file using
```{r 03-DataIngestionMunging-16a}
brca_expression <- readxl::read_excel('../../data/BreastCancer.xlsx', sheet='Expression')
```

---
class: middle, center

# Data export

---

## Data export

```{r 03-DataIngestionMunging-17, echo=F}
b <- tribble(
  ~Type, ~Function, ~Package,~Notes,
  "csv", "write_csv", "readr", "Takes care of formatting",
  "csv", "write.csv", "base", "Built in",
  "csv", "fwrite", "data.table", "Fastest",
  "Excel", "write.xlsx", "openxlsx",'',
  'sas7bdat','write_sas', 'haven','SAS format',
  'json','write_json', 'jsonlite','JSON format'
)
knitr::kable(b, format='html')
```

We'll often save tabular results using these functions

.footnote[These can also be useful for exporting results, but the R Markdown related packages are better for that]

---
class: middle,center,inverse

# Simplifying Import/Export

---

We'll be using a package that makes this easier. 

It's called **rio** and it has two basic functions: `import` and `export`.

The `rio` package uses the different packages mentioned earlier but unifies it into a single syntax

For example:

```{r, eval=F}
rio::import('../../data/clinical_data_breast_cancer_modified.csv')
```

--

**rio** reads the end of the file being imported or exported and decides which functions from which package should be used for the job. 

**rio** accesses different packages that are right for each job, so you don't have to.

---

You can also import multiple sheets from Excel, or multiple objects from .RData files, into a list of data frames

```{r, echo=T, eval=T}
dat <- rio::import_list('../../data/BreastCancer.xlsx')
```

.pull-left[
```{r}
class(dat)
names(dat)

```
]
.pull-right[
```{r}
for(i in 1:length(dat)){
  print(paste0('The object dat$',names(dat)[i],' is of class ', class(dat[[i]])))
}
```

]

---

## Saving your work

You would often like to store intermediate datasets, and final datasets, so that you can access them quickly.

There are several ways of saving even large datasets so that they can be quickly accessed. 

| Function  | Package | Example                                  | Retrieving the stored data          |
|-----------|---------|------------------------------------------|-------------------------------------|
| saveRDS   | base    | `saveRDS(weather, file = 'weather.rds')` | `weather <- readRDS('weather.rds')` |
| write_fst | fst     | `write_fst(weather, file='weather.fst')` | `weather <- read_fst('weather.fst')` |

These methods are meant for storing .fatinline[single objects]

---

## Saving your work

If you want to store all of your objects into a single file, you can store them in a .RData file.

```{r rda, eval=FALSE}
save.image(file="<filename>.RData")
```

To keep multiple specified objects in a .RData file,

```{r rda2, eval=FALSE}
save(<obj1>, <obj2>, <obj3>, file = "<filename>.RData")
```

------

## Retrieving your work

You can retrieve the objects in a .RData file using the function `load`. 

```{r load, eval=FALSE}
load(file = "<filename>.RData")
```

This will store each object in its original name in your R environment. 






